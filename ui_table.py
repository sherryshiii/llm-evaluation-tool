import importlib
import pandas as pd
import re
import asyncio
from typing import Tuple, Optional, Dict, List, Any
import gradio as gr
from utils.resp_parser import process_responses
from config import get_model_by_key
from llm_client import multi_request
import os
from ui_shared import create_common_inputs, create_model_selector, create_prompt_inputs, price_change_handler
from utils.comparator import COMPARE_FUNCTIONS

# é»˜è®¤æç¤ºè¯
DEFAULT_SYS_PROMPT = """ä½ æ˜¯ä¸€ä¸ªå®¢æœåŠ©ç†ï¼Œéœ€è¦å¸®åŠ©å®¢æœä»Žå®¢æˆ·çš„æé—®ä¸­è¯†åˆ«å‡ºå®¢æˆ·çš„æ‰€åœ¨ä½ç½®ã€‚è¯·è¯†åˆ«å¯¹è¯ä¸­çš„è¡Œæ”¿åŒºåˆ’å’Œåœ°å€ä¿¡æ¯ï¼Œä»Žæ–‡æœ¬ä¸­åˆ†æžå’Œè¯†åˆ«çœã€å¸‚ã€åŒºåŽ¿å’Œè¯¦ç»†åœ°å€ï¼Œå¹¶è¾“å‡ºä¸ºJSONæ ¼å¼
éµå¾ªè§„åˆ™ï¼š
å¦‚æžœè¯´æ˜Žäº†æˆ¿å­ä¸åœ¨æŸåœ°ï¼Œä¸è¦è¯†åˆ«å‡ºæ¥
å¦‚æžœåŒ…å«å¤šä¸ªè¡Œæ”¿åŒºï¼Œåªè¾“å‡ºä¸€ä¸ªä¸»è¦çš„ã€å¯èƒ½ä»£è¡¨æˆ¿äº§ä½ç½®çš„åœ°å€ã€‚ä¾‹å¦‚"æˆ‘åœ¨ä¸Šæµ·ä¸Šç­ï¼Œå®¶åœ¨æ­¦æ±‰"ï¼Œåº”è§†ä¸ºæ­¦æ±‰å¸‚
ä¸è¦å›žç­”æˆ¿åž‹ã€é¢ç§¯ç­‰ä¸Žä½ç½®æ— å…³çš„ä¿¡æ¯
ä¸€å®šä¸è¦å›žç­”å…¶ä»–å†…å®¹ï¼Œåªè¾“å‡ºJSONï¼Œkeyæ˜¯ province / city / district / street
é¢„æœŸè¾“å‡ºJSONæ ¼å¼ç¤ºä¾‹ï¼š{"province":"","city":"","district":"","street":""}"""
DEFAULT_USER_PROMPT = "å®¢æˆ·å‘é€çš„æ¶ˆæ¯æ˜¯ï¼š$input"

def create_tab_table():
    """åˆ›å»ºè¡¨æ ¼è¯„æµ‹æ ‡ç­¾é¡µçš„UIç•Œé¢"""
    with gr.TabItem("è¡¨æ ¼è¯„æµ‹", id="table"):
        with gr.Row():
            with gr.Column():
                sys_prompt_input, user_prompt_input = create_prompt_inputs(
                    sys_prompt=DEFAULT_SYS_PROMPT,
                    user_prompt=DEFAULT_USER_PROMPT
                )
            
            with gr.Column():
                response_format, temperature, parser_selector = create_common_inputs(
                    resp_parser=""
                )
                comparator = gr.Dropdown(
                    choices=[(v, k) for k, v in COMPARE_FUNCTIONS.items()],
                    label="è¯„ä¼°æ–¹å¼",
                    value="compare_text"
                )
                file_upload = gr.File(label="ä¸Šä¼ è¡¨æ ¼æ–‡ä»¶ (CSV/XLS/XLSX)", file_types=[".csv", ".xls", ".xlsx"], height=100)
                use_example_btn = gr.Button("ä½¿ç”¨ç¤ºä¾‹è¡¨æ ¼")
            
            with gr.Column():
                price_selector, model_selector = create_model_selector()

        submit_btn = gr.Button("æäº¤", variant="primary")
        
        stats_table = gr.Dataframe(
            label="ç»Ÿè®¡ä¿¡æ¯",
            headers=["æ¨¡åž‹", "æœ€å°å“åº”æ—¶é—´", "æœ€å¤§å“åº”æ—¶é—´", "å¹³å‡å“åº”æ—¶é—´", "å¹³å‡è¾“å…¥Token", "å¹³å‡è¾“å‡ºToken", "å®Œæˆæ•°", "å®ŒæˆçŽ‡", "æ­£ç¡®æ•°", "æ­£ç¡®çŽ‡"]
        )

        output_table = gr.Dataframe(
            label="è¡¨æ ¼å†…å®¹"
        )
        
        download_file = gr.DownloadButton(label="ä¸‹è½½è¡¨æ ¼")
        
        # ç»‘å®šä»·æ ¼ç­›é€‰äº‹ä»¶
        price_selector.change(
            fn=price_change_handler,
            inputs=price_selector,
            outputs=model_selector
        )
        
        # ä½¿ç”¨ç¤ºä¾‹è¡¨æ ¼æŒ‰é’®äº‹ä»¶
        use_example_btn.click(
            fn=lambda: "table_demo.xlsx",
            outputs=file_upload
        )
        
        # è¯„ä¼°æŒ‰é’®äº‹ä»¶
        submit_btn.click(
            fn=table_submit_handler,
            inputs=[
                file_upload, 
                sys_prompt_input, 
                user_prompt_input, 
                model_selector, 
                comparator,
                parser_selector,
                response_format,
                temperature
            ],
            outputs=[stats_table, output_table, download_file]
        )

def extract_template_vars(prompt: str):
    """ä»Žæç¤ºè¯ä¸­æå–å˜é‡å"""
    return re.findall(r"\$([a-zA-Z_][a-zA-Z0-9_]*)", prompt or "")

def check_table_columns(df: pd.DataFrame, vars_list):
    """æ£€æŸ¥è¡¨æ ¼ä¸­æ˜¯å¦åŒ…å«æ‰€éœ€çš„åˆ—"""
    missing = [v for v in vars_list if f"${v}" not in df.columns]
    return missing

async def table_submit_handler(file, sys_prompt, user_prompt, selected_models, comparator, parser_type, response_format, temperature, progress=gr.Progress()) -> Tuple[Optional[pd.DataFrame], Optional[pd.DataFrame], Optional[str]]:
    # è¾“å…¥éªŒè¯
    if file is None:
        raise gr.Error("è¯·ä¸Šä¼ è¡¨æ ¼æ–‡ä»¶")
    if not selected_models:
        raise gr.Error("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªæ¨¡åž‹")
        
    # è¯»å–è¡¨æ ¼æ–‡ä»¶
    file_path = file.name if hasattr(file, 'name') else str(file)
    if file_path.endswith('.csv'):
        df = pd.read_csv(file_path)
    elif file_path.endswith(('.xls', '.xlsx')):
        df = pd.read_excel(file_path)
    else:
        raise gr.Error("ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼Œè¯·ä¸Šä¼ CSVæˆ–XLS/XLSXæ–‡ä»¶")

    # é¢„å¤„ç†è¡¨æ ¼æ•°æ®
    if "æœŸæœ›ç­”æ¡ˆ" in df.columns:
        df["æœŸæœ›ç­”æ¡ˆ"] = df["æœŸæœ›ç­”æ¡ˆ"].fillna("")

    # éªŒè¯æç¤ºè¯å˜é‡
    vars_in_prompt = set(extract_template_vars(sys_prompt) + extract_template_vars(user_prompt))
    if not vars_in_prompt:
        raise gr.Error("æœªåœ¨Promptä¸­æ£€æµ‹åˆ°å˜é‡ï¼ˆå¦‚ $inputï¼‰")
        
    # éªŒè¯è¡¨æ ¼åˆ—
    missing = check_table_columns(df, vars_in_prompt)
    if missing:
        raise gr.Error(f"è¡¨æ ¼ä¸­ç¼ºå°‘ä»¥ä¸‹åˆ—: {', '.join(missing)}")

    # æž„å»ºå¹¶å‘ä»»åŠ¡
    all_tasks = []
    task_mapping = []  # è®°å½•æ¯ä¸ªä»»åŠ¡å¯¹åº”çš„(æ¨¡åž‹, è¡Œç´¢å¼•)
    
    for row_idx, row in df.iterrows():
        for model_key in selected_models:
            # æ›¿æ¢æç¤ºè¯ä¸­çš„å˜é‡
            row_vars = {v: row.get(f"${v}", "") for v in vars_in_prompt}
            sys_prompt_filled = sys_prompt
            user_prompt_filled = user_prompt
            for k, v in row_vars.items():
                sys_prompt_filled = sys_prompt_filled.replace(f"${k}", str(v) if v is not None else "")
                user_prompt_filled = user_prompt_filled.replace(f"${k}", str(v) if v is not None else "")
            
            # æ·»åŠ ä»»åŠ¡
            all_tasks.append({
                "sys_prompt": sys_prompt_filled,
                "user_prompt": user_prompt_filled,
                "model_key": model_key,
                "response_format": response_format,
                "temperature": temperature
            })
            task_mapping.append((model_key, row_idx))
    
    # å¹¶å‘æ‰§è¡Œæ¨¡åž‹è¯·æ±‚
    results = await multi_request(all_tasks, progress)
    
    # å¹¶å‘å¤„ç†å“åº”ç»“æžœ
    contents = [r["content"] for r in results]
    processed_contents = await process_responses(contents, parser_type)
    
    # æ•´ç†å¤„ç†ç»“æžœ
    model_results = {model_key: [""] * len(df) for model_key in selected_models}
    for (model_key, row_idx), processed in zip(task_mapping, processed_contents):
        model_results[model_key][row_idx] = processed

    # æ›´æ–°DataFrameå¹¶è¯„ä¼°ç»“æžœ
    model_cols = []  # ç”¨äºŽå­˜å‚¨æ‰€æœ‰æ¨¡åž‹ç›¸å…³çš„åˆ—å
    for model_key in selected_models:
        model_info = get_model_by_key(model_key)
        col_name = model_info['showname']
        df[col_name] = model_results[model_key]
        model_cols.append(col_name)
        
        # è¯„ä¼°ç»“æžœ
        if "æœŸæœ›ç­”æ¡ˆ" in df.columns:
            judge_col = f"{model_info['showname']}ç»“æžœ"  # æ¯ä¸ªæ¨¡åž‹ä¸€ä¸ªç»“æžœåˆ—
            module = importlib.import_module("utils.comparator")
            compare_func = getattr(module, comparator, None)
            
            # è®¡ç®—æ­£ç¡®çŽ‡
            judge_results = []
            for model_ans, expected in zip(df[col_name], df["æœŸæœ›ç­”æ¡ˆ"]):
                model_ans = "" if pd.isna(model_ans) else str(model_ans)
                expected = "" if pd.isna(expected) else str(expected)
                is_correct = compare_func(model_ans, expected)
                judge_results.append(1 if is_correct else 0)
            df[judge_col] = judge_results
            model_cols.append(judge_col)

    # æ·»åŠ å¹³å‡ç»“æžœåˆ—
    if "æœŸæœ›ç­”æ¡ˆ" in df.columns:
        judge_cols = [col for col in df.columns if col.endswith("ç»“æžœ")]
        df["å¹³å‡ç»“æžœ"] = df[judge_cols].mean(axis=1).round(1)
        # å°†å¹³å‡ç»“æžœåˆ—ç§»åŠ¨åˆ°æœŸæœ›ç­”æ¡ˆåŽé¢
        cols = df.columns.tolist()
        expect_idx = cols.index("æœŸæœ›ç­”æ¡ˆ")
        cols.remove("å¹³å‡ç»“æžœ")
        cols.insert(expect_idx + 1, "å¹³å‡ç»“æžœ")
        df = df[cols]

    # æ·»åŠ æ±‡æ€»ç»Ÿè®¡
    if "æœŸæœ›ç­”æ¡ˆ" in df.columns:
        summary_row = pd.Series(index=df.columns, data="")
        for model_key in selected_models:
            model_info = get_model_by_key(model_key)
            judge_col = f"{model_info['showname']}ç»“æžœ"
            correct_count = sum(1 for x in df[judge_col] if x == 1)
            summary_row[judge_col] = str(correct_count)
        df = pd.concat([df, pd.DataFrame([summary_row])], ignore_index=True)

    # è®¡ç®—ç»Ÿè®¡æ•°æ®
    stats_data = []
    for model_key in selected_models:
        model_info = get_model_by_key(model_key)
        model_results = [r for r, (m, _) in zip(results, task_mapping) if m == model_key]
        
        # è®¡ç®—ç»Ÿè®¡æ•°æ®
        completed_results = [r for r in model_results if r["time"] is not None]
        completed_count = len(completed_results)
        completion_rate = completed_count / len(model_results) * 100
        
        min_time = min(r["time"] for r in completed_results) if completed_count > 0 else "-"
        max_time = max(r["time"] for r in completed_results) if completed_count > 0 else "-"
        avg_time = sum(r["time"] for r in completed_results) / completed_count if completed_count > 0 else "-"
        avg_input_tokens = sum(r["input_tokens"] for r in completed_results) / completed_count if completed_count > 0 else "-"
        avg_output_tokens = sum(r["output_tokens"] for r in completed_results) / completed_count if completed_count > 0 else "-"
        
        # è®¡ç®—æ­£ç¡®çŽ‡
        correct_count = 0
        accuracy = 0
        if "æœŸæœ›ç­”æ¡ˆ" in df.columns:
            judge_col = f"{model_info['showname']}ç»“æžœ"
            correct_count = sum(1 for x in df[judge_col] if x == 1)
            accuracy = correct_count / (len(df)-1) * 100
            
        stats_data.append([
            model_info['showname'],
            f"{round(min_time)}ms",
            f"{round(max_time)}ms",
            f"{round(avg_time)}ms",
            round(avg_input_tokens),
            round(avg_output_tokens),
            completed_count,
            f"{round(completion_rate, 1)}%",
            correct_count,
            f"{round(accuracy, 1)}%"
        ])
    
    stats_df = pd.DataFrame(
        stats_data,
        columns=["æ¨¡åž‹", "æœ€å°å“åº”æ—¶é—´", "æœ€å¤§å“åº”æ—¶é—´", "å¹³å‡å“åº”æ—¶é—´", "å¹³å‡è¾“å…¥Token", "å¹³å‡è¾“å‡ºToken", "å®Œæˆæ•°", "å®ŒæˆçŽ‡", "æ­£ç¡®æ•°", "æ­£ç¡®çŽ‡"]
    )

    # ä¿å­˜ç»“æžœ
    os.makedirs("runtime", exist_ok=True)
    result_file = "runtime/result.csv"
    df.to_csv(result_file, index=False)

    # é™åˆ¶æ˜¾ç¤ºçš„æ•°æ®é‡
    display_df = df.head(100)
    total_rows = len(df)
    display_rows = len(display_df)
    
    # å¦‚æžœæ•°æ®è¢«ç¼©å‡ï¼Œæ˜¾ç¤ºæç¤ºä¿¡æ¯
    label_text = f"è¡¨æ ¼å†…å®¹ï¼ˆðŸ“Š æ€»æ•°æ®é‡ï¼š{total_rows} æ¡ï¼Œå½“å‰æ˜¾ç¤ºï¼š{display_rows} æ¡ï¼Œæ›´å¤šè¯·ä¸‹è½½è¡¨æ ¼ï¼‰" if total_rows > display_rows else "è¡¨æ ¼å†…å®¹"

    # è®¾ç½®åˆ—å®½ï¼šç»“æžœåˆ—120ï¼Œå…¶ä»–åˆ—250
    column_widths = [120 if col.endswith("ç»“æžœ") else 250 for col in display_df.columns]

    return stats_df, gr.update(value=display_df, label=label_text, column_widths=column_widths), result_file